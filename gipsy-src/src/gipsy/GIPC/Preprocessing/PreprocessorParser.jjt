/*
 * Preprocessor Grammar File
 * Author: Serguei Mokhov, mokhov@cs.concordia.ca
 *
 * $Id: PreprocessorParser.jjt,v 1.31 2005/11/08 23:36:42 aihua_wu Exp $
 */


/*
 * OPTIONS
 */
options
{
	LOOKAHEAD = 2;
	NODE_DEFAULT_VOID = true;
	FORCE_LA_CHECK = true;
	STATIC = false;
}


/*
 * COMPILATION PART
 */

PARSER_BEGIN(PreprocessorParser)
package gipsy.GIPC.Preprocessing;

import gipsy.GIPC.util.*;


/**
 * Preprocessor Parser to chunkanize a GIPSY program into parts.
 *
 * NOTE: Automatically generated by JavaCC. When making changes to this
 * file, please also update PreprocessorParser.jjt accordingly.
 *
 * $Id: PreprocessorParser.jjt,v 1.31 2005/11/08 23:36:42 aihua_wu Exp $
 *
 * @author Serguei Mokhov, mokhov@cs.concordia.ca
 * @version $Revision: 1.31 $
 * @since 1.0.0
 */
public class PreprocessorParser
{
	/**
	 * The root of the Preprocessor's AST.
	 */
	protected SimpleNode oPreprocessorASTRoot = null;

	/**
	 * Generic parse method.
	 * @throws ParseException if parse error happened
	 */
	public void parse()
	throws ParseException
	{
		this.oPreprocessorASTRoot = startParse();
	}

	/**
	 * Gets the root of the Preprocessor's AST.
	 * @return the AST root of the preprocessed code segments
	 */
	public SimpleNode getPreprocessorASTRoot()
	{
		return this.oPreprocessorASTRoot;
	}
}
PARSER_END(PreprocessorParser)

/*
 * The Preprocessor Grammar in BNF
 *
 * GIPSY ->
 * 	DECLARATIONS CODESEGMENTS
 *
 * DECLARATIONS ->
 * 	FUNCDECLS DECLARATIONS
 * 	| TYPEDECLS DECLARATIONS
 *  | {}
 *
 * FUNCDECLS ->
 * 	"#funcdecl" PROTOTYPES
 *
 * TYPEDECLS ->
 * 	"#typedecl" TYPES
 *
 * PROTOTYPES ->
 * 	[ "immutable" ] TYPE ID "(" TYPELIST ")" ( ":" LANGID ":" URL ( ":" ID | {} ) | {} ) ";" PROTOTYPES
 * 	| {}
 *
 * TYPES ->
 * 	TYPE ";" TYPES
 * 	| {}
 *
 * TYPELIST ->
 * 	TYPE ("," TYPELIST | {})
 * 	| {}
 *
 * CODESEGMENT ->
 * 	LANGDATA ( LANGID | EOF )
 *
 * CODESEGMENTS ->
 * 	CODESEGMENT CODESEGMENTS
 * 	| {}
 *
 * URL -> CHARACTER_LITERAL | STRING_LITERAL
 *
 * TYPE ->
 * 	ID
 * 	| "int"
 * 	| "double"
 * 	| "bool"
 * 	| "float"
 * 	| "char"
 * 	| "string"
 * 	| "void"
 */



/*
 * TOKEN DECLARATION
 */

SKIP : /* WHITE SPACE */
{
	  " "
	| "\t"
	| "\n"
	| "\r"
	| "\f"
}

SPECIAL_TOKEN : /* COMMENTS */
{
	  <SINGLE_LINE_COMMENT: "//"  (~["\n","\r"])* ("\n"|"\r"|"\r\n")>
	| <FORMAL_COMMENT:      "/**" (~["*"])* "*" ("*" | (~["*","/"] (~["*"])* "*"))* "/">
	| <MULTI_LINE_COMMENT:  "/*"  (~["*"])* "*" ("*" | (~["*","/"] (~["*"])* "*"))* "/">
}

TOKEN : /* SEPARATORS */
{
	  <LPAREN: "(">
	| <RPAREN: ")">
	| <COLON: ":">
	| <SEMICOLON: ";">
	| <COMMA: ",">
	| <DOUBLE_QUOTE: "\"">
	| <SINGLE_QUOTE: "'">
}

TOKEN : /* RESERVED WORDS AND LITERALS */
{
	  <TYPEDECL:  "#typedecl">
	| <FUNCDECL:  "#funcdecl">
	| <IPLDECL:   "#ipldecl">
	| <IMMUTABLE: "immutable">
}

TOKEN : /* DATA TYPES*/
{
	  <INT:     "int">
	| <DOUBLE:  "double">
	| <BOOLEAN: "bool">
	| <FLOAT:   "float">
	| <CHAR:    "char">
	| <STRING:  "string">
	| <VOID:    "void">
}

TOKEN : /* LITERALS */
{
	<CHARACTER_LITERAL:
	    "'"
	    (   (~["'","\\","\n","\r"])
	       | ("\\"
	            ( ["n","t","b","r","f","\\","'","\""]
	            | ["0"-"7"] ( ["0"-"7"] )?
	            | ["0"-"3"] ["0"-"7"] ["0"-"7"]
	            )
	         )
	    )*
	    "'"
	>

|	<STRING_LITERAL:
	    "\""
	    (   (~["\"","\\","\n","\r"])
	        | ("\\"
	            ( ["n","t","b","r","f","\\","'","\""]
	            | ["0"-"7"] ( ["0"-"7"] )?
	            | ["0"-"3"] ["0"-"7"] ["0"-"7"]
	            )
	          )
	    )*
	    "\""
	>
}

/*
 * NOTE: need to keep this one in sync with:
 *   GIPL.jjt, IndexicalLucid.jjt, and PreprocessorParser.jjt.
 *   JGIPL.jjt and JIndexicalLucid.jjt are generated.
 */
TOKEN : /* IDENTIFIERS */
{
	<ID: <LETTER> (<LETTER>|<DIGIT>)*>

	| <#LETTER:
		[
			"\u0024",
			"\u0041"-"\u005a",
			"\u005f",
			"\u0061"-"\u007a",
			"\u00c0"-"\u00d6",
			"\u00d8"-"\u00f6",
			"\u00f8"-"\u00ff",
			"\u0100"-"\u1fff",
			"\u3040"-"\u318f",
			"\u3300"-"\u337f",
			"\u3400"-"\u3d2d",
			"\u4e00"-"\u9fff",
			"\uf900"-"\ufaff"
		]
	  >

	| <#DIGIT:
		[
			"\u0030"-"\u0039",
			"\u0660"-"\u0669",
			"\u06f0"-"\u06f9",
			"\u0966"-"\u096f",
			"\u09e6"-"\u09ef",
			"\u0a66"-"\u0a6f",
			"\u0ae6"-"\u0aef",
			"\u0b66"-"\u0b6f",
			"\u0be7"-"\u0bef",
			"\u0c66"-"\u0c6f",
			"\u0ce6"-"\u0cef",
			"\u0d66"-"\u0d6f",
			"\u0e50"-"\u0e59",
			"\u0ed0"-"\u0ed9",
			"\u1040"-"\u1049"
		]
	  >
}  /* Suppose they are UNICODE */

TOKEN : /* LANGUAGE IDENTIFIERS */
{
	  <LANGID: <HASH> <CAPITAL_LETTER> ( <CAPITAL_LETTER> | <DIGIT> )*>
	| <#HASH: "#">
	| <#CAPITAL_LETTER: ["A"-"Z"]>
}

TOKEN : /* LANG DATA a.k.a. RAW TEXT OF A SOURCE CODE IN A GIVEN LANGUAGE */
{
	//<LANGDATA: ( <LANGID> ( [ "\u0000" - "\u00FF" ] )* )>
	//<LANGDATA: <LANGID> (( [ "\u0000" - "\uFFFF" ] )*)? <HASH>>
	//<LANGDATA: <LANGID> (~["#"])* "#" ("#" | (~["#"] (~["#"])* "#"))* "#">
	//       "/*"  (~["*"])* "*" ("*" | (~["*","/"] (~["*"])* "*"))* "/"
	//<LANGDATA: "#" (~["#"])* "#" ("#" | (~["#"]     (~["#"])* "#"))* "#">
	//<LANGDATA: <LANGID> (~["#"] (["A"-"Z"])+)*>
	//<LANGDATA: <LANGID> (~["#"])* "#"(["A"-"Z"])*>
	
	/* 
	 * Kind of kludgy, but works.
	 * Anything that has a legal "#" in it is screwed.
	 * TODO: provide an \# sequence or make the original
	 * plan work ... duh!
	 */
	<LANGDATA: <LANGID> (~["#"])*>

	//<LANGDATA: "#" (~["#"])*>
}


/*
 * ------
 * SYNTAX
 * ------
 */

/**
 * The parsing begins here.
 * @throws ParseException if there was a syntax error
 */
SimpleNode startParse() #START : {}
{
	gipsy() <EOF>
	{
		return jjtThis;
	}
}

/**
 * The staring producion of the GIPSY program
 * GIPSY ->
 * 	DECLARATIONS CODESEGMENTS
 */
void gipsy() : {}
{
	declarations() codeSegments()
}

/**
 * DECLARATIONS ->
 * 	FUNCDECLS DECLARATIONS
 * 	| TYPEDECLS DECLARATIONS
 *  | {}
 */
void declarations() : {}
{
	[
		  funcDecls() declarations()
		| typeDecls() declarations()
	]
}

/**
 * FUNCDECLS ->
 * 	"#funcdecl" PROTOTYPES
 */
void funcDecls() #FUNCDECLS : {}
{
	<FUNCDECL> prototypes()
}

/**
 * TYPEDECLS ->
 * 	"#typedecl" TYPES
 */
void typeDecls() #TYPEDECLS : {}
{
	<TYPEDECL> types()
	| <IPLDECL> iplTypes()
}

void iplTypes() #IPLTYPES : {}
{
	[ iplType() iplTypes() ]
}

void iplType() #IPLTYPE : {}
{
	<LANGID> codeSegment()
}


/**
 * PROTOTYPES ->
 * 	PROTOTYPE ";" PROTOTYPES
 * 	| {}
 */
void prototypes() #PROTOTYPES : {}
{
	[ prototype() <SEMICOLON> prototypes() ]
}

/**
 * PROTOTYPE -> TYPE ID "(" TYPELIST ")" EMBED
 */
void prototype() #PROTOTYPE :
{
	Token oReturnType;
	Token oTokenFID;
	Token oImmutable = null;
}
{
	/*
	 * Should parse:
	 * immutable int foo(int a, float b)
	 * int foo(int a, float b):#JAVA:"ftp://newton/pub/Foo.class"
	 * int foo(int a, float b):#JAVA:"ftp://newton/pub/Foo.class":bar
	 */
	[ oImmutable = <IMMUTABLE> ] oReturnType = type() oTokenFID = <ID> <LPAREN> typeList() <RPAREN> [ <COLON> embed() ]
	{
		jjtThis.setLexeme(oReturnType.image + ":" + oTokenFID.image);
	}
}

/**
 * EMBED -> ( LANGID ":" URL ( ":" ID | {} ) | {} )
 */
void embed() #EMBED :
{
	Token oTokenURL;
	Token oTokenLang;
	Token oTokenIDMap = null;
}
{
	oTokenLang = <LANGID> oTokenURL = url() [ <COLON> oTokenIDMap = <ID> ]
	{
		String strAltName = oTokenIDMap == null ? "": oTokenIDMap.image;
		jjtThis.setLexeme(oTokenURL.image + "|" + oTokenLang.image + "|" + strAltName);
	}
}

/**
 * TYPES ->
 * 	  ID        ";" TYPES
 * 	| ID ":" ID ";" TYPES
 * 	| {}
 */
void types() #TYPES : {}
{
	[ <ID> [ <COLON> <ID> ] <SEMICOLON> types() ]
}

/**
 * TYPELIST ->
 * 	TYPE ("," TYPELIST | {})
 * 	| {}
 */
void typeList() : {}
{
	// XXX: Do I need an ID??? [ type() <ID> [ <COMMA> typeList() ] ]
	[ type() [ <COMMA> typeList() ] ]
}

/**
 * CODESEGMENT ->
 * 	LANGDATA ( LANGID | EOF ).
 */
void codeSegment() #CODESEGMENT:
{
	Token oToken;
}
{
	oToken = <LANGDATA>
	{
		// Make sure we remember what the contents was
		jjtThis.setLexeme(oToken.image);
	}
}

/**
 * CODESEGMENTS ->
 * 	CODESEGMENT CODESEGMENTS
 * 	| {}.
 */
void codeSegments() : {}
{
	[ codeSegment() codeSegments() ]
}

/**
 * URL -> CHARACTER_LITERAL | STRING_LITERAL.
 */
Token url() #URL :
{
	Token oToken;
}
{
	(
		  oToken = <CHARACTER_LITERAL>
		| oToken = <STRING_LITERAL>
	)
	{
		jjtThis.setLexeme(oToken.image);
		return oToken;
	}
}

/**
 * TYPE ->
 * 	ID
 * 	| "int"
 * 	| "double"
 *  | "bool"
 * 	| "float"
 * 	| "char"
 * 	| "string"
 *  | "void"
 */
Token type() #TYPE :
{
	Token oToken;
}
{
	(
		  oToken = <ID>
		| oToken = <INT>
		| oToken = <BOOLEAN>
		| oToken = <DOUBLE>
		| oToken = <FLOAT>
		| oToken = <CHAR>
		| oToken = <STRING>
		| oToken = <VOID>
	)
	{
		jjtThis.setLexeme(oToken.image);
		return oToken;
	}
}

// EOF
